import 'dart:async';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';
import 'package:speech_to_text/speech_to_text.dart';
import 'audio_recorder.dart';
import 'stt_service.dart';
import 'models/audio_result.dart';

class AudioSTTManager {
  final AudioRecorderWrapper _audioRecorder = AudioRecorderWrapper();
  final STTService _sttService = STTService();

  bool _isRecording = false;
  bool _isSTTActive = false;

  // ì´ˆê¸°í™”
  Future<AudioResult> initialize() async {
    final sttResult = await _sttService.initialize();
    if (!sttResult.success) {
      return sttResult;
    }
    return AudioResult.success();
  }

  // ê¶Œí•œ ì²´í¬
  Future<bool> checkPermissions() async {
    return await _sttService.hasPermission();
  }

  // 1. ë‹¨ìˆœ ë…¹ìŒë§Œ
  Future<AudioResult> startRecording({String? path}) async {
    if (_isRecording) {
      return AudioResult.error('ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤');
    }

    final result = await _audioRecorder.startRecording(path: path);
    if (result.success) {
      _isRecording = true;
    }
    return result;
  }

  Future<AudioResult> stopRecording() async {
    if (!_isRecording) {
      return AudioResult.error('ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
    }

    final result = await _audioRecorder.stopRecording();
    _isRecording = false;
    return result;
  }

  Future<AudioResult> pauseRecording() async {
    if (!_isRecording) {
      return AudioResult.error('ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
    }
    return await _audioRecorder.pauseRecording();
  }

  Future<AudioResult> resumeRecording() async {
    if (!_isRecording) {
      return AudioResult.error('ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
    }
    return await _audioRecorder.resumeRecording();
  }

  Future<AudioResult> cancelRecording() async {
    if (!_isRecording) {
      return AudioResult.error('ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
    }

    final result = await _audioRecorder.cancelRecording();
    _isRecording = false;
    return result;
  }

  // 2. ì‹¤ì‹œê°„ STTë§Œ
  Future<AudioResult> startSTT({
    required Function(String) onPartialResult,
    required Function(String) onFinalResult,
    String localeId = 'ko_KR',
  }) async {
    if (_isSTTActive) {
      return AudioResult.error('ì´ë¯¸ STTê°€ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤');
    }

    final result = await _sttService.startListening(
      onPartialResult: onPartialResult,
      onFinalResult: onFinalResult,
      localeId: localeId,
    );

    if (result.success) {
      _isSTTActive = true;
    }
    return result;
  }

  // ì—°ì† STT ì‹œì‘ (ìë™ ì¬ì‹œì‘)
  Future<AudioResult> startContinuousSTT({
    required Function(String) onPartialResult,
    required Function(String) onFinalResult,
    String localeId = 'ko_KR',
  }) async {
    if (_isSTTActive) {
      return AudioResult.error('ì´ë¯¸ STTê°€ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤');
    }

    print('ğŸ”„ ì—°ì† STT ëª¨ë“œ ì‹œì‘');

    final result = await _sttService.startContinuousListening(
      onPartialResult: onPartialResult,
      onFinalResult: onFinalResult,
      localeId: localeId,
    );

    if (result.success) {
      _isSTTActive = true;
    }
    return result;
  }

  Future<AudioResult> stopSTT() async {
    if (!_isSTTActive) {
      return AudioResult.error('STTê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤');
    }

    final result = await _sttService.stopListening();
    _isSTTActive = false;
    return result;
  }

  Future<AudioResult> cancelSTT() async {
    if (!_isSTTActive) {
      return AudioResult.error('STTê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤');
    }

    final result = await _sttService.cancelListening();
    _isSTTActive = false;
    return result;
  }

  // 3. ë…¹ìŒ + ì‹¤ì‹œê°„ STT ë³‘ë ¬ ì²˜ë¦¬
  Future<AudioResult> startRecordingWithSTT({
    String? path,
    required Function(String) onPartialResult,
    required Function(String) onFinalResult,
    String localeId = 'ko_KR',
    bool continuousMode = true, // ê¸°ë³¸ì ìœ¼ë¡œ ì—°ì† ëª¨ë“œ ì‚¬ìš©
  }) async {
    // ë…¹ìŒ ì‹œì‘
    final recordResult = await startRecording(path: path);
    if (!recordResult.success) {
      return recordResult;
    }

    // STT ì‹œì‘ (ì—°ì† ëª¨ë“œ or ì¼ë°˜ ëª¨ë“œ)
    final sttResult = continuousMode
        ? await startContinuousSTT(
            onPartialResult: onPartialResult,
            onFinalResult: onFinalResult,
            localeId: localeId,
          )
        : await startSTT(
            onPartialResult: onPartialResult,
            onFinalResult: onFinalResult,
            localeId: localeId,
          );

    if (!sttResult.success) {
      // STT ì‹¤íŒ¨í•˜ë©´ ë…¹ìŒë„ ì •ì§€
      await stopRecording();
      return sttResult;
    }

    return AudioResult.success();
  }

  Future<AudioResult> stopRecordingWithSTT() async {
    // ë³‘ë ¬ë¡œ ë‘˜ ë‹¤ ì •ì§€
    final recordFuture = stopRecording();
    final sttFuture = stopSTT();

    final results = await Future.wait([recordFuture, sttFuture]);

    final recordResult = results[0];
    final sttResult = results[1];

    // ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë¦¬í„´
    if (!recordResult.success) return recordResult;
    if (!sttResult.success) return sttResult;

    // ì„±ê³µì‹œ ë…¹ìŒ íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ ëª¨ë‘ í¬í•¨
    return AudioResult.success(
      filePath: recordResult.filePath,
      transcription: sttResult.transcription,
      duration: recordResult.duration,
    );
  }

  Future<AudioResult> pauseRecordingWithSTT() async {
    final recordFuture = pauseRecording();
    final sttFuture = cancelSTT(); // STTëŠ” ì¼ì‹œì •ì§€ê°€ ì—†ì–´ì„œ cancel

    final results = await Future.wait([recordFuture, sttFuture]);

    if (!results[0].success) return results[0];
    if (!results[1].success) return results[1];

    return AudioResult.success();
  }

  Future<AudioResult> resumeRecordingWithSTT({
    required Function(String) onPartialResult,
    required Function(String) onFinalResult,
    String localeId = 'ko_KR',
  }) async {
    final recordFuture = resumeRecording();
    final sttFuture = startSTT(
      onPartialResult: onPartialResult,
      onFinalResult: onFinalResult,
      localeId: localeId,
    );

    final results = await Future.wait([recordFuture, sttFuture]);

    if (!results[0].success) return results[0];
    if (!results[1].success) return results[1];

    return AudioResult.success();
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  Future<String> createCustomPath({
    required String fileName,
    bool useDocumentsDirectory = true,
  }) async {
    try {
      final directory = useDocumentsDirectory
          ? await getApplicationDocumentsDirectory()
          : await getTemporaryDirectory();
      return '${directory.path}/$fileName';
    } catch (e) {
      final tempDir = await getTemporaryDirectory();
      return '${tempDir.path}/$fileName';
    }
  }

  Future<List<LocaleName>> getAvailableLocales() async {
    return await _sttService.getAvailableLocales();
  }

  // ë³¼ë¥¨ ë ˆë²¨ ìŠ¤íŠ¸ë¦¼ (íŒŒí˜• ê·¸ë¦¬ê¸°ìš©)
  Stream<Amplitude> onAmplitudeChanged(Duration interval) {
    return _audioRecorder.onAmplitudeChanged(interval);
  }

  Future<Amplitude> getAmplitude() async {
    return await _audioRecorder.getAmplitude();
  }

  // ìƒíƒœ í™•ì¸
  bool get isRecording => _isRecording;
  bool get isSTTActive => _isSTTActive;
  bool get isRecorderAvailable => _audioRecorder != null;
  bool get isSTTAvailable => _sttService.isAvailable;

  // í˜„ì¬ STT í…ìŠ¤íŠ¸
  String get currentSTTText => _sttService.currentText;

  Future<bool> isRecordingPaused() async {
    return await _audioRecorder.isPaused();
  }

  // ë¦¬ì†ŒìŠ¤ í•´ì œ
  void dispose() {
    _audioRecorder.dispose();
    _sttService.dispose();
    _isRecording = false;
    _isSTTActive = false;
  }
}
